{\rtf1\ansi\ansicpg1252\cocoartf2818
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset0 HelveticaNeue-Bold;\f1\fnil\fcharset0 HelveticaNeue;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0\cname textColor;}
\paperw11900\paperh16840\margl1440\margr1440\vieww25400\viewh25740\viewkind0
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f0\b\fs28 \cf2 Directory Structure
\f1\b0 \
data_efficiency/: Active learning, boundary logistic, and disagree ensemble models. \
post_decision/: Ensemble model using features x1- x15 (including log-odds of the majority ratio). Log-odds of x14 and x15 analysis.\
pre_decision/: Ensemble and logistic regression models trained on features x1-x13. Includes logistic regression model trained on features x1-x15 (for convenience).\
prep/: Baseline model, class distribution, and feature importance. \
stacking_post_models/: Base classifiers (logistic, Naive Bayes, decision tree, random forest) trained on x1-\uc0\u1093 15. \
stacking_pre_models/: Base classifiers trained on x1-x13. test/: Disagree ensemble models for test data (Kaggle). \
utils/: Data loaders (including feature engineering) and learning curve plotting functions.\
\

\f0\b How to run?\

\f1\b0 1. Run pre_decision/logistic_model.py to create pickle files for stacking_pre_models/logistic_regression_model.pkl and stacking_post_models/logistic_regression_model.pkl\
2. Then, run stacking_pre_models and stacking_post_models to export models as pickle files\
3. Now, ensemble model is ready to run as it imports the pickle files of its classifiers
\f0\b \
\
Test predictions run on Kaggle
\f1\b0 \
test/logistic_test.csv for the logistic model trained for RQ1\
test/ensemble_complex_test.csv for the ensemble model trained for RQ1\
test/ensemble_disagree_complex.csv for the modified ensemble model used for RQ3, and is the best Kaggle performer}